
            self.indicators_history.append(
                [
                    #(self.df.loc[current_step, 'MACD'] + 1472.21 ) / (1211.07 + 1472.21) ,
                    (self.df.loc[current_step, 'ichi_a_15m'] - 3190.13)/(66270 - 3190.13),
                    (self.df.loc[current_step, 'ichi_b_15m'] - 3197.35)/(65572.76 - 3197.35),
                    (self.df.loc[current_step, 'ichi_base_line_15m'] - 3180.08)/(66345 - 3180.08),
                    (self.df.loc[current_step, 'ichi_conversion_line_15m'] - 3174.27)/(66652 - 3174.27),

                 ])
           
    lookback_window_size = 12
    test_window = 24 * 30    # 30 days

    ## Training Section:
    train_df = df[:-test_window-lookback_window_size]
    agent = CustomAgent(lookback_window_size=lookback_window_size,
                        learning_rate=0.0001, epochs=5, optimizer=Adam, batch_size=24
                                                        , model="Dense", state_size=10+4)
    
    total_average = deque(maxlen=2)
    
        self.punish_value += self.net_worth * 0.000002
        
        X = Flatten(input_shape=input_shape)(X_input)
        X = Dense(512, activation="relu")(X)
        X = Dense(256, activation="relu")(X)
        X = Dense(64, activation="relu")(X)
        output = Dense(self.action_space, activation="softmax")(X)
        
        V = Flatten(input_shape=input_shape)(X_input)
        V = Dense(512, activation="relu")(V)
        V = Dense(256, activation="relu")(V)
        V = Dense(64, activation="relu")(V)
        value = Dense(1, activation=None)(V)
        